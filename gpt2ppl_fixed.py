"""
This code a slight modification of perplexity by hugging face
https://huggingface.co/docs/transformers/perplexity

Both this code and the orignal code are published under the MIT license.

by Burhan Ul tayyab and Nicholas Chua
"""

import torch
import re
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
from collections import OrderedDict


class GPT2PPL:
    def __init__(self, device=None, model_id="gpt2"):
        # Auto-detect device if not specified
        if device is None:
            if torch.cuda.is_available():
                self.device = "cuda"
                print("CUDA is available. Using GPU.")
            else:
                self.device = "cpu"
                print("CUDA not available. Using CPU.")
        else:
            # Validate the specified device
            if device == "cuda" and not torch.cuda.is_available():
                print("Warning: CUDA requested but not available. Falling back to CPU.")
                self.device = "cpu"
            else:
                self.device = device
        
        self.model_id = model_id
        print(f"Loading model '{model_id}' on device: {self.device}")
        
        try:
            self.model = GPT2LMHeadModel.from_pretrained(model_id).to(self.device)
            self.tokenizer = GPT2TokenizerFast.from_pretrained(model_id)
        except Exception as e:
            print(f"Error loading model: {e}")
            if self.device == "cuda":
                print("Attempting to fall back to CPU...")
                self.device = "cpu"
                self.model = GPT2LMHeadModel.from_pretrained(model_id).to(self.device)
                self.tokenizer = GPT2TokenizerFast.from_pretrained(model_id)

        self.max_length = self.model.config.n_positions
        self.stride = 512
        
    def getResults(self, threshold):
        if threshold < 60:
            label = 0
            return "The Text is generated by AI.", label
        elif threshold < 80:
            label = 0
            return "The Text is most probably contain parts which are generated by AI. (require more text for better Judgement)", label
        else:
            label = 1
            return "The Text is written by Human.", label

    def __call__(self, sentence):
        """
        Takes in a sentence split by full stop
        and print the perplexity of the total sentence

        split the lines based on full stop and find the perplexity of each sentence and print
        average perplexity

        Burstiness is the max perplexity of each sentence
        """
        results = OrderedDict()

        total_valid_char = re.findall("[a-zA-Z0-9]+", sentence)
        total_valid_char = sum([len(x) for x in total_valid_char]) # finds len of all the valid characters a sentence

        if total_valid_char < 100:
            return {"status": "Please input more text (min 100 characters)"}, "Please input more text (min 100 characters)"
        
        lines = re.split(r'(?<=[.?!][ \[\(])|(?<=\n)\s*',sentence)
        lines = list(filter(lambda x: (x is not None) and (len(x) > 0), lines))

        ppl = self.getPPL(sentence)
        print(f"Perplexity {ppl}")
        results["Perplexity"] = ppl

        offset = ""
        Perplexity_per_line = []
        for i, line in enumerate(lines):
            if re.search("[a-zA-Z0-9]+", line) == None:
                continue
            if len(offset) > 0:
                line = offset + line
                offset = ""
            # remove the new line pr space in the first sentence if exists
            if line[0] == "\n" or line[0] == " ":
                line = line[1:]
            if line[-1] == "\n" or line[-1] == " ":
                line = line[:-1]
            elif line[-1] == "[" or line[-1] == "(":
                offset = line[-1]
                line = line[:-1]
            ppl = self.getPPL(line)
            Perplexity_per_line.append(ppl)
        print(f"Perplexity per line {sum(Perplexity_per_line)/len(Perplexity_per_line)}")
        results["Perplexity per line"] = sum(Perplexity_per_line)/len(Perplexity_per_line)

        print(f"Burstiness {max(Perplexity_per_line)}")
        results["Burstiness"] = max(Perplexity_per_line)

        out, label = self.getResults(results["Perplexity per line"])
        results["label"] = label

        return results, out

    def getPPL(self,sentence):
        encodings = self.tokenizer(sentence, return_tensors="pt")
        seq_len = encodings.input_ids.size(1)

        nlls = []
        likelihoods = []
        prev_end_loc = 0
        for begin_loc in range(0, seq_len, self.stride):
            end_loc = min(begin_loc + self.max_length, seq_len)
            trg_len = end_loc - prev_end_loc
            input_ids = encodings.input_ids[:, begin_loc:end_loc].to(self.device)
            target_ids = input_ids.clone()
            target_ids[:, :-trg_len] = -100

            with torch.no_grad():
                outputs = self.model(input_ids, labels=target_ids)
                neg_log_likelihood = outputs.loss * trg_len
                likelihoods.append(neg_log_likelihood)

            nlls.append(neg_log_likelihood)

            prev_end_loc = end_loc
            if end_loc == seq_len:
                break
        ppl = int(torch.exp(torch.stack(nlls).sum() / end_loc))
        return ppl


"""
Modified version of GPT2PPL with composite scoring
Add this to your existing gpt2ppl_fixed.py file
"""


class CompositeScorer:
    def normalize_score(self, value, min_val=0, max_val=300):
        """Normalize scores to 0-100 range"""
        return min(100, max(0, (value - min_val) / (max_val - min_val) * 100))

    def get_composite_score(self, overall_ppl, per_line_ppl, burstiness):
        """
        Weighted linear combination - most interpretable method
        """
        # Normalize all scores to 0-100 range
        norm_overall = self.normalize_score(overall_ppl, 10, 200)
        norm_per_line = self.normalize_score(per_line_ppl, 10, 200)
        norm_burstiness = self.normalize_score(burstiness, 20, 400)

        # Weights: per_line is most important for classification
        weights = {
            'per_line': 0.6,  # Primary classifier
            'burstiness': 0.3,  # Creativity indicator
            'overall': 0.1  # General complexity
        }

        composite = (weights['per_line'] * norm_per_line +
                     weights['burstiness'] * norm_burstiness +
                     weights['overall'] * norm_overall)

        return composite

    def interpret_score(self, score):
        """Convert composite score to interpretation"""
        if score < 30:
            return "Highly likely AI-generated", 0
        elif score < 50:
            return "Likely AI-generated", 0
        elif score < 70:
            return "Uncertain - mixed or borderline", 0.5
        elif score < 85:
            return "Likely human-written", 1
        else:
            return "Highly likely human-written", 1


# Add this method to your existing GPT2PPL class
def enhanced_call(self, sentence):
    """
    Enhanced version of __call__ with composite scoring
    Replace or add alongside your existing __call__ method
    """
    results = OrderedDict()
    scorer = CompositeScorer()

    total_valid_char = re.findall("[a-zA-Z0-9]+", sentence)
    total_valid_char = sum([len(x) for x in total_valid_char])

    if total_valid_char < 100:
        return {"status": "Please input more text (min 100 characters)"}, "Please input more text (min 100 characters)"

    lines = re.split(r'(?<=[.?!][ \[\(])|(?<=\n)\s*', sentence)
    lines = list(filter(lambda x: (x is not None) and (len(x) > 0), lines))

    ppl = self.getPPL(sentence)
    results["Perplexity"] = ppl

    offset = ""
    Perplexity_per_line = []
    for i, line in enumerate(lines):
        if re.search("[a-zA-Z0-9]+", line) == None:
            continue
        if len(offset) > 0:
            line = offset + line
            offset = ""
        if line[0] == "\n" or line[0] == " ":
            line = line[1:]
        if line[-1] == "\n" or line[-1] == " ":
            line = line[:-1]
        elif line[-1] == "[" or line[-1] == "(":
            offset = line[-1]
            line = line[:-1]
        ppl = self.getPPL(line)
        Perplexity_per_line.append(ppl)

    avg_per_line = sum(Perplexity_per_line) / len(Perplexity_per_line)
    max_burstiness = max(Perplexity_per_line)

    results["Perplexity per line"] = avg_per_line
    results["Burstiness"] = max_burstiness

    # Calculate composite score
    composite_score = scorer.get_composite_score(ppl, avg_per_line, max_burstiness)
    interpretation, confidence = scorer.interpret_score(composite_score)

    results["Composite Score"] = round(composite_score, 2)
    results["Interpretation"] = interpretation
    results["Confidence"] = confidence

    # Additional metrics
    variation_ratio = max_burstiness / max(avg_per_line, 1)
    results["Variation Ratio"] = round(variation_ratio, 2)

    # Print results
    print(f"Perplexity: {ppl}")
    print(f"Perplexity per line: {avg_per_line:.2f}")
    print(f"Burstiness: {max_burstiness}")
    print(f"Composite Score: {composite_score:.2f}/100")
    print(f"Interpretation: {interpretation}")
    print(f"Variation Ratio: {variation_ratio:.2f}")

    return results, interpretation
